{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 155163,
     "status": "ok",
     "timestamp": 1741921600265,
     "user": {
      "displayName": "Jaya Jareda",
      "userId": "03997002092589873276"
     },
     "user_tz": -330
    },
    "id": "xxE7omEGlmFE",
    "outputId": "b0e3025a-54ec-447f-f33b-41181fb93553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /content/ABB_segment_1.mp3...\n",
      "Processing /content/ABB_segment_2 (1).mp3...\n",
      "Processing /content/ABB_segment_3 (1).mp3...\n",
      "All data saved to /content/output_folder/output.csv\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import csv\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def transcribe_audio(api_key, audio_file):\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "    with open(audio_file, \"rb\") as file:\n",
    "        response = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=file,\n",
    "            response_format=\"verbose_json\"\n",
    "        )\n",
    "\n",
    "    return response\n",
    "\n",
    "def compute_dropoff(audio_file):\n",
    "    \"\"\"Compute the degree of speakerâ€™s voice gradually decreasing over an utterance.\"\"\"\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "    # Compute short-term energy over time\n",
    "    frame_length = 2048\n",
    "    hop_length = 512\n",
    "    energy = np.array([\n",
    "        np.sum(np.abs(y[i : i + frame_length]) ** 2)\n",
    "        for i in range(0, len(y) - frame_length, hop_length)\n",
    "    ])\n",
    "\n",
    "    # Compute drop-off as the ratio of last energy value to first energy value\n",
    "    dropoff_ratio = energy[-1] / energy[0] if energy[0] > 0 else 0\n",
    "    return dropoff_ratio\n",
    "\n",
    "def save_to_csv(results, output_file=\"/content/output_folder/output.csv\"):\n",
    "    \"\"\"Save dropoff values to a CSV file.\"\"\"\n",
    "    os.makedirs(\"/content/output_folder\", exist_ok=True)\n",
    "\n",
    "    with open(output_file, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"File Name\", \"Dropoff Ratio\"])\n",
    "        writer.writerows(results)\n",
    "\n",
    "def process_multiple_files(api_key, audio_files, output_file):\n",
    "    results = []\n",
    "\n",
    "    for audio_file in audio_files:\n",
    "        print(f\"Processing {audio_file}...\")\n",
    "        transcribe_audio(api_key, audio_file)  # Using Whisper API\n",
    "        dropoff_ratio = compute_dropoff(audio_file)\n",
    "        results.append([os.path.basename(audio_file), dropoff_ratio])\n",
    "\n",
    "    save_to_csv(results, output_file)\n",
    "    print(f\"All data saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    API_KEY = \"\"  # Replace with your OpenAI API key\n",
    "    AUDIO_FILES = [\n",
    "        \"/content/ABB_segment_1.mp3\",\n",
    "        \"/content/ABB_segment_2 (1).mp3\",\n",
    "        \"/content/ABB_segment_3 (1).mp3\"\n",
    "    ]  # Replace with your list of audio files\n",
    "    OUTPUT_FILE = \"/content/output_folder/output.csv\"\n",
    "\n",
    "    process_multiple_files(API_KEY, AUDIO_FILES, OUTPUT_FILE)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNIE5Tv83Thaa0R05Q+0NFO",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
