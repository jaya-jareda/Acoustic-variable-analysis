{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122234,
     "status": "ok",
     "timestamp": 1742305252284,
     "user": {
      "displayName": "Jaya Jareda",
      "userId": "03997002092589873276"
     },
     "user_tz": -330
    },
    "id": "1KTtQU0cgpt4",
    "outputId": "62af7c1a-89ef-4c46-e029-e9c6770b2bc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /content/ABB_segment_2 (1).mp3...\n",
      "Processing /content/Adani Wilmar Limited (NSEI_AWL) Jan-31-2024 - Audio_segment_2.mp3...\n",
      "Processing /content/Adani Wilmar Limited (NSEI_AWL) Jul-30-2024 - Audio_segment_2.mp3...\n",
      "All data saved to /content/output_folder/output.csv\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import csv\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def transcribe_audio(api_key, audio_file):\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "    with open(audio_file, \"rb\") as file:\n",
    "        response = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=file,\n",
    "            response_format=\"verbose_json\"\n",
    "        )\n",
    "\n",
    "    return response\n",
    "\n",
    "def compute_pitch_variation(audio_file):\n",
    "    \"\"\"Compute the variation in pitch to analyze expressive use of tone.\"\"\"\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "\n",
    "    # Extract pitch values where magnitude is above a threshold\n",
    "    pitch_values = pitches[magnitudes > np.median(magnitudes)]\n",
    "\n",
    "    if len(pitch_values) == 0:\n",
    "        return 0  # No pitch variations detected\n",
    "\n",
    "    pitch_variation = np.std(pitch_values)  # Standard deviation of pitch values\n",
    "    return pitch_variation\n",
    "\n",
    "def save_to_csv(results, output_file=\"/content/output_folder/output.csv\"):\n",
    "    \"\"\"Save pitch variations to a CSV file.\"\"\"\n",
    "    os.makedirs(\"/content/output_folder\", exist_ok=True)\n",
    "\n",
    "    with open(output_file, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"File Name\", \"Pitch Variation\"])\n",
    "        writer.writerows(results)\n",
    "\n",
    "def process_multiple_files(api_key, audio_files, output_file):\n",
    "    results = []\n",
    "\n",
    "    for audio_file in audio_files:\n",
    "        print(f\"Processing {audio_file}...\")\n",
    "        transcribe_audio(api_key, audio_file)  # Using Whisper API\n",
    "        pitch_variation = compute_pitch_variation(audio_file)\n",
    "        results.append([os.path.basename(audio_file), pitch_variation])\n",
    "\n",
    "    save_to_csv(results, output_file)\n",
    "    print(f\"All data saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    API_KEY = \"\"\n",
    "  # Replace with your OpenAI API key\n",
    "    AUDIO_FILES = [\n",
    "        \"/content/ABB_segment_2 (1).mp3\",\n",
    "        \"/content/Adani Wilmar Limited (NSEI_AWL) Jan-31-2024 - Audio_segment_2.mp3\",\n",
    "        \"/content/Adani Wilmar Limited (NSEI_AWL) Jul-30-2024 - Audio_segment_2.mp3\"\n",
    "    ]  # Replace with your list of audio files\n",
    "    OUTPUT_FILE = \"/content/output_folder/output.csv\"\n",
    "\n",
    "    process_multiple_files(API_KEY, AUDIO_FILES, OUTPUT_FILE)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOQh2HMUh8uovogYFHLoyJs",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
